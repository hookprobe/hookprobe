//! # Machine Learning Module
//!
//! Provides ML-based threat classification, starting with DGA (Domain
//! Generation Algorithm) detection. Uses feature extraction on domain names
//! with an optional ONNX Runtime backend for neural network inference.
//!
//! ## DGA Detection
//!
//! DGA domains are generated by malware to contact command-and-control (C2)
//! servers. They have characteristic statistical properties:
//!
//! - High character entropy
//! - Unusual consonant/vowel ratios
//! - Low n-gram frequency scores
//! - Non-dictionary character patterns
//!
//! ## Architecture
//!
//! ```text
//! Domain string
//!     |
//!     v
//! [Feature Extraction] --> 8 features
//!     |
//!     v
//! [ONNX Model] --available--> neural prediction
//!     |
//!     +--not available--> [Hash-based fallback] --> heuristic prediction
//!     |
//!     v
//! (is_dga: bool, confidence: f32)
//! ```
//!
//! ## Features
//!
//! | Index | Feature | Description |
//! |-------|---------|-------------|
//! | 0 | `domain_length` | Total character count |
//! | 1 | `digit_ratio` | Fraction of digits |
//! | 2 | `vowel_ratio` | Fraction of vowels |
//! | 3 | `consonant_ratio` | Fraction of consonants |
//! | 4 | `entropy` | Shannon entropy of characters |
//! | 5 | `bigram_avg` | Average bigram frequency score |
//! | 6 | `trigram_avg` | Average trigram frequency score |
//! | 7 | `max_consonant_seq` | Longest consecutive consonant run |

use std::collections::HashMap;

// ---------------------------------------------------------------------------
// Feature extraction
// ---------------------------------------------------------------------------

/// Extracted features from a domain name for DGA classification.
#[derive(Debug, Clone)]
pub struct DomainFeatures {
    /// Total length of the domain (excluding TLD).
    pub domain_length: f32,
    /// Ratio of digit characters (0-9).
    pub digit_ratio: f32,
    /// Ratio of vowel characters (aeiou).
    pub vowel_ratio: f32,
    /// Ratio of consonant characters.
    pub consonant_ratio: f32,
    /// Shannon entropy of the character distribution.
    pub entropy: f32,
    /// Average bigram (2-character) frequency score.
    pub bigram_avg: f32,
    /// Average trigram (3-character) frequency score.
    pub trigram_avg: f32,
    /// Maximum consecutive consonant sequence length.
    pub max_consonant_seq: f32,
}

impl DomainFeatures {
    /// Convert features to a fixed-size array for model input.
    pub fn to_array(&self) -> [f32; 8] {
        [
            self.domain_length,
            self.digit_ratio,
            self.vowel_ratio,
            self.consonant_ratio,
            self.entropy,
            self.bigram_avg,
            self.trigram_avg,
            self.max_consonant_seq,
        ]
    }
}

/// Extract features from a domain name.
///
/// Strips the TLD and any trailing dots before analysis.
pub fn extract_features(domain: &str) -> DomainFeatures {
    // Strip TLD: take everything before the last dot
    let base_domain = strip_tld(domain).to_lowercase();

    if base_domain.is_empty() {
        return DomainFeatures {
            domain_length: 0.0,
            digit_ratio: 0.0,
            vowel_ratio: 0.0,
            consonant_ratio: 0.0,
            entropy: 0.0,
            bigram_avg: 0.0,
            trigram_avg: 0.0,
            max_consonant_seq: 0.0,
        };
    }

    let chars: Vec<char> = base_domain.chars().collect();
    let len = chars.len() as f32;

    // Character counts
    let digits = chars.iter().filter(|c| c.is_ascii_digit()).count() as f32;
    let vowels = chars
        .iter()
        .filter(|c| "aeiou".contains(**c))
        .count() as f32;
    let consonants = chars
        .iter()
        .filter(|c| c.is_ascii_alphabetic() && !"aeiou".contains(**c))
        .count() as f32;

    // Shannon entropy
    let entropy = compute_entropy(&base_domain);

    // Bigram and trigram frequency scores
    let bigram_avg = compute_ngram_score(&base_domain, 2);
    let trigram_avg = compute_ngram_score(&base_domain, 3);

    // Maximum consecutive consonant sequence
    let max_consonant_seq = max_consecutive_consonants(&base_domain) as f32;

    DomainFeatures {
        domain_length: len,
        digit_ratio: digits / len,
        vowel_ratio: vowels / len,
        consonant_ratio: consonants / len,
        entropy,
        bigram_avg,
        trigram_avg,
        max_consonant_seq,
    }
}

/// Strip the TLD from a domain name.
///
/// Returns the portion before the last dot. Handles multi-level TLDs
/// simply by taking the second-level domain.
fn strip_tld(domain: &str) -> &str {
    let domain = domain.trim_end_matches('.');

    // For simplicity, strip everything after the last dot
    match domain.rfind('.') {
        Some(pos) => &domain[..pos],
        None => domain,
    }
}

/// Compute Shannon entropy of a string.
fn compute_entropy(s: &str) -> f32 {
    if s.is_empty() {
        return 0.0;
    }

    let mut freq: HashMap<char, usize> = HashMap::new();
    for c in s.chars() {
        *freq.entry(c).or_insert(0) += 1;
    }

    let len = s.len() as f32;
    let mut entropy: f32 = 0.0;

    for &count in freq.values() {
        let p = count as f32 / len;
        if p > 0.0 {
            entropy -= p * p.log2();
        }
    }

    entropy
}

/// Compute the average n-gram frequency score.
///
/// Uses a reference frequency table for English text. Lower scores
/// indicate more random (DGA-like) character combinations.
fn compute_ngram_score(s: &str, n: usize) -> f32 {
    if s.len() < n {
        return 0.0;
    }

    let bytes = s.as_bytes();
    let ngram_count = s.len() - n + 1;
    let mut total_score = 0.0f32;

    for i in 0..ngram_count {
        let ngram = &bytes[i..i + n];
        total_score += ngram_frequency_score(ngram);
    }

    total_score / ngram_count as f32
}

/// Look up the frequency score for an n-gram.
///
/// Returns a value between 0.0 (very rare) and 1.0 (very common).
/// Uses a simple heuristic based on character pair commonality.
fn ngram_frequency_score(ngram: &[u8]) -> f32 {
    // Common English bigrams score higher
    // This is a simplified heuristic; production would use a real frequency table
    let common_bigrams: &[&[u8]] = &[
        b"th", b"he", b"in", b"er", b"an", b"re", b"on", b"at", b"en", b"nd",
        b"ti", b"es", b"or", b"te", b"of", b"ed", b"is", b"it", b"al", b"ar",
        b"st", b"to", b"nt", b"ng", b"se", b"ha", b"as", b"ou", b"io", b"le",
        b"ve", b"co", b"me", b"de", b"hi", b"ri", b"ro", b"ic", b"ne", b"ea",
    ];

    if ngram.len() == 2 {
        if common_bigrams.contains(&ngram) {
            return 0.8;
        }
        // Check if both characters are alphabetic
        if ngram.iter().all(|b| b.is_ascii_alphabetic()) {
            return 0.3;
        }
        return 0.1;
    }

    // For trigrams, check if the first two characters form a common bigram
    if ngram.len() >= 3 {
        let first_two = &ngram[..2];
        if common_bigrams.contains(&first_two) {
            return 0.6;
        }
        if ngram.iter().all(|b| b.is_ascii_alphabetic()) {
            return 0.25;
        }
        return 0.1;
    }

    0.1
}

/// Find the longest consecutive consonant sequence.
fn max_consecutive_consonants(s: &str) -> usize {
    let mut max_run = 0;
    let mut current_run = 0;

    for c in s.chars() {
        if c.is_ascii_alphabetic() && !"aeiou".contains(c) {
            current_run += 1;
            max_run = max_run.max(current_run);
        } else {
            current_run = 0;
        }
    }

    max_run
}

// ---------------------------------------------------------------------------
// DGA Classifier
// ---------------------------------------------------------------------------

/// DGA domain classifier with feature extraction and optional ONNX inference.
///
/// When the `ml` feature is enabled and an ONNX model is loaded, uses
/// neural network inference. Otherwise, falls back to a hash-based
/// heuristic classifier.
pub struct DGAClassifier {
    /// Classification threshold (features above this are flagged as DGA).
    threshold: f32,
    /// Whether an ONNX model is loaded.
    #[cfg(feature = "ml")]
    onnx_session: Option<()>, // TODO: Replace with ort::Session
    /// Known legitimate domain patterns for false positive suppression.
    whitelist_patterns: Vec<String>,
}

impl DGAClassifier {
    /// Create a new DGA classifier with default settings.
    pub fn new() -> Self {
        Self {
            threshold: 0.65,
            #[cfg(feature = "ml")]
            onnx_session: None,
            whitelist_patterns: default_whitelist(),
        }
    }

    /// Create a DGA classifier with a custom threshold.
    pub fn with_threshold(threshold: f32) -> Self {
        Self {
            threshold,
            #[cfg(feature = "ml")]
            onnx_session: None,
            whitelist_patterns: default_whitelist(),
        }
    }

    /// Load an ONNX model for neural network inference.
    ///
    /// Only available when compiled with the `ml` feature.
    #[cfg(feature = "ml")]
    pub fn load_model(&mut self, _model_path: &str) -> Result<(), String> {
        // TODO: Load ONNX model using ort crate
        // let session = ort::Session::builder()?
        //     .with_optimization_level(ort::GraphOptimizationLevel::Level3)?
        //     .commit_from_file(model_path)?;
        // self.onnx_session = Some(session);
        todo!("Implement ONNX model loading")
    }

    /// Classify a domain as DGA or legitimate.
    ///
    /// # Returns
    /// `(is_dga, confidence)` where confidence is between 0.0 and 1.0.
    pub fn is_dga(&self, domain: &str) -> (bool, f32) {
        // Check whitelist first
        if self.is_whitelisted(domain) {
            return (false, 0.0);
        }

        let features = extract_features(domain);

        // Try ONNX inference first
        #[cfg(feature = "ml")]
        if self.onnx_session.is_some() {
            return self.onnx_predict(&features);
        }

        // Fallback: heuristic classification
        self.heuristic_predict(&features)
    }

    /// ONNX neural network prediction.
    #[cfg(feature = "ml")]
    fn onnx_predict(&self, _features: &DomainFeatures) -> (bool, f32) {
        // TODO: Run ONNX inference
        // let input = features.to_array();
        // let outputs = self.onnx_session.as_ref().unwrap().run(...)?;
        // let confidence = outputs[0].extract_tensor::<f32>()?[0];
        // (confidence > self.threshold, confidence)
        todo!("Implement ONNX inference")
    }

    /// Heuristic DGA prediction based on extracted features.
    ///
    /// Computes a weighted score from statistical features. This serves
    /// as the fallback when no ONNX model is available.
    fn heuristic_predict(&self, features: &DomainFeatures) -> (bool, f32) {
        let mut score: f32 = 0.0;

        // High entropy is suspicious (DGA domains are random-looking)
        // Normal domains: ~3.0-3.5 entropy, DGA: ~3.8-4.5+
        if features.entropy > 4.0 {
            score += 0.3;
        } else if features.entropy > 3.5 {
            score += 0.15;
        }

        // High digit ratio is suspicious
        if features.digit_ratio > 0.3 {
            score += 0.2;
        } else if features.digit_ratio > 0.15 {
            score += 0.1;
        }

        // Low vowel ratio is suspicious (random strings have few vowels)
        if features.vowel_ratio < 0.15 {
            score += 0.15;
        } else if features.vowel_ratio < 0.25 {
            score += 0.05;
        }

        // Long consecutive consonant sequences are suspicious
        if features.max_consonant_seq >= 5.0 {
            score += 0.2;
        } else if features.max_consonant_seq >= 4.0 {
            score += 0.1;
        }

        // Low n-gram scores indicate unusual character combinations
        if features.bigram_avg < 0.2 {
            score += 0.15;
        }
        if features.trigram_avg < 0.15 {
            score += 0.1;
        }

        // Very long domains are suspicious
        if features.domain_length > 20.0 {
            score += 0.1;
        }

        // Clamp to [0, 1]
        let confidence = score.min(1.0);
        let is_dga = confidence >= self.threshold;

        (is_dga, confidence)
    }

    /// Check if a domain matches a whitelist pattern.
    fn is_whitelisted(&self, domain: &str) -> bool {
        let d = domain.to_lowercase();
        self.whitelist_patterns
            .iter()
            .any(|pattern| d.ends_with(pattern) || d == *pattern)
    }
}

/// Default whitelist of known-legitimate domain patterns.
fn default_whitelist() -> Vec<String> {
    vec![
        "google.com".to_string(),
        "googleapis.com".to_string(),
        "gstatic.com".to_string(),
        "microsoft.com".to_string(),
        "windows.net".to_string(),
        "apple.com".to_string(),
        "icloud.com".to_string(),
        "amazon.com".to_string(),
        "amazonaws.com".to_string(),
        "cloudflare.com".to_string(),
        "github.com".to_string(),
        "githubusercontent.com".to_string(),
        "akamaiedge.net".to_string(),
        "akamai.net".to_string(),
        "fastly.net".to_string(),
    ]
}

// ---------------------------------------------------------------------------
// Tests
// ---------------------------------------------------------------------------

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_extract_features_normal_domain() {
        let features = extract_features("google.com");
        assert!(features.domain_length > 0.0);
        assert!(features.entropy > 0.0);
        assert!(features.vowel_ratio > 0.2); // "google" has good vowel ratio
    }

    #[test]
    fn test_extract_features_dga_like() {
        let features = extract_features("x7kq9mn3rz.evil.com");
        assert!(features.digit_ratio > 0.2);
        assert!(features.entropy > 3.0);
    }

    #[test]
    fn test_extract_features_empty() {
        let features = extract_features("");
        assert_eq!(features.domain_length, 0.0);
        assert_eq!(features.entropy, 0.0);
    }

    #[test]
    fn test_entropy_single_char() {
        let entropy = compute_entropy("aaaaaa");
        assert_eq!(entropy, 0.0); // All same character = zero entropy
    }

    #[test]
    fn test_entropy_varied() {
        let entropy = compute_entropy("abcdef");
        assert!(entropy > 2.0); // High variety = high entropy
    }

    #[test]
    fn test_max_consecutive_consonants() {
        assert_eq!(max_consecutive_consonants("strength"), 6); // strngth
        assert_eq!(max_consecutive_consonants("aeiou"), 0);
        assert_eq!(max_consecutive_consonants("abc"), 2); // bc
    }

    #[test]
    fn test_strip_tld() {
        assert_eq!(strip_tld("example.com"), "example");
        assert_eq!(strip_tld("sub.example.com"), "sub.example");
        assert_eq!(strip_tld("example.com."), "example.com");
        assert_eq!(strip_tld("localhost"), "localhost");
    }

    #[test]
    fn test_dga_classifier_normal() {
        let classifier = DGAClassifier::new();

        // Normal domains should not be flagged
        let (is_dga, confidence) = classifier.is_dga("example.com");
        assert!(!is_dga, "Normal domain flagged as DGA (confidence: {})", confidence);
    }

    #[test]
    fn test_dga_classifier_suspicious() {
        let classifier = DGAClassifier::with_threshold(0.5);

        // Random-looking domain should be flagged
        let (is_dga, confidence) = classifier.is_dga("x7kq9mn3rzpt5b2w.evil.com");
        // This should have high digit ratio, high entropy, low vowels
        assert!(
            confidence > 0.3,
            "Suspicious domain should have higher confidence: {}",
            confidence
        );
    }

    #[test]
    fn test_dga_classifier_whitelist() {
        let classifier = DGAClassifier::new();
        let (is_dga, _) = classifier.is_dga("fonts.googleapis.com");
        assert!(!is_dga, "Whitelisted domain should not be flagged");
    }

    #[test]
    fn test_ngram_frequency_common() {
        let score = ngram_frequency_score(b"th");
        assert!(score > 0.5, "Common bigram should score high");
    }

    #[test]
    fn test_ngram_frequency_rare() {
        let score = ngram_frequency_score(b"7x");
        assert!(score < 0.3, "Rare bigram should score low");
    }
}
