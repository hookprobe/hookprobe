"""
Fortress REST API Routes

Provides REST API endpoints for:
- VLAN management
- Device management
- Security metrics (QSecBit)
- DNS statistics
- System status
"""

import json
import logging
from datetime import datetime
from flask import jsonify, request
from flask_login import login_required, current_user

from . import api_bp
from ..auth.decorators import admin_required, operator_required
from ...security_utils import safe_error_message

logger = logging.getLogger(__name__)

# Import lib modules (with fallback for development)
DB_AVAILABLE = False
try:
    import sys
    from pathlib import Path
    sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent / 'lib'))
    from database import get_db
    from vlan_manager import get_vlan_manager
    from device_manager import get_device_manager
    DB_AVAILABLE = True
except ImportError:
    pass


def db_required(f):
    """Decorator to check database availability."""
    from functools import wraps
    @wraps(f)
    def decorated(*args, **kwargs):
        if not DB_AVAILABLE:
            return jsonify({'error': 'Database not available'}), 503
        return f(*args, **kwargs)
    return decorated


# ========================================
# Health & Status
# ========================================

@api_bp.route('/health')
def health():
    """Health check endpoint."""
    return jsonify({
        'status': 'healthy',
        'tier': 'fortress',
        'version': '5.5.0',
        'timestamp': datetime.now().isoformat()
    })


@api_bp.route('/version')
def version():
    """Version info."""
    return jsonify({'version': '5.5.0', 'product': 'Fortress'})


@api_bp.route('/status')
@login_required
def status():
    """
    Unified system status endpoint.

    Returns comprehensive status including QSecBit, devices, DNS, WAN, tunnel.
    This is the primary status endpoint - /api/dashboard/stats mirrors this data.
    """
    from pathlib import Path
    import json as json_mod

    data = {
        'tier': 'fortress',
        'version': '5.5.0',
        'database': DB_AVAILABLE,
        'timestamp': datetime.now().isoformat()
    }

    # QSecBit stats (file-based fallback)
    qsecbit_data = {'score': 0.85, 'status': 'GREEN', 'components': {}}
    try:
        stats_file = Path('/opt/hookprobe/fortress/data/qsecbit_stats.json')
        if stats_file.exists():
            with open(stats_file, 'r') as f:
                qs = json_mod.load(f)
                qsecbit_data = {
                    'score': qs.get('score', 0.85),
                    'status': qs.get('rag_status', 'GREEN'),
                    'components': qs.get('components', {}),
                    'threats_detected': qs.get('threats_detected', 0)
                }
    except Exception:
        pass

    # If database available, prefer DB data
    if DB_AVAILABLE:
        try:
            db = get_db()
            qsecbit = db.get_latest_qsecbit()
            if qsecbit:
                qsecbit_data = {
                    'score': float(qsecbit['score']),
                    'status': qsecbit['rag_status'],
                    'components': qsecbit.get('components', {}),
                    'threats_detected': qsecbit.get('threats_detected', 0)
                }
        except Exception:
            pass

    data['qsecbit'] = qsecbit_data

    # Device counts
    device_count = 0
    if DB_AVAILABLE:
        try:
            device_counts = get_device_manager().get_device_count()
            device_count = device_counts.get('total', 0)
            data['devices'] = device_counts
        except Exception:
            pass
    if device_count == 0:
        # Fallback: ARP status JSON file (generated by host agent)
        try:
            arp_file = Path('/var/lib/hookprobe/arp-status.json')
            if arp_file.exists():
                import json as json_mod_arp
                with open(arp_file, 'r') as f:
                    arp_data = json_mod_arp.load(f)
                    device_count = len([d for d in arp_data.values() if d.get('online', False)])
        except Exception:
            pass
    if device_count == 0:
        # Last fallback: ARP table via ip neigh
        try:
            import subprocess
            result = subprocess.run(['ip', 'neigh', 'show'], capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                device_count = len([l for l in result.stdout.strip().split('\n') if l and 'FAILED' not in l])
        except Exception:
            pass
    data['device_count'] = device_count

    # DNS blocked count
    dns_blocked = 0
    try:
        dns_file = Path('/opt/hookprobe/fortress/data/dnsxai_stats.json')
        if dns_file.exists():
            with open(dns_file, 'r') as f:
                dns_blocked = json_mod.load(f).get('blocked_today', 0)
    except Exception:
        pass
    data['dns_blocked'] = dns_blocked

    # Threat summary
    if DB_AVAILABLE:
        try:
            data['threats'] = get_db().get_threat_summary(hours=24)
        except Exception:
            pass
    data['threats_blocked'] = qsecbit_data.get('threats_detected', 0)

    # VLAN count
    vlan_count = 5
    if DB_AVAILABLE:
        try:
            vlans = get_vlan_manager().get_vlans()
            vlan_count = len(vlans) if vlans else 5
        except Exception:
            pass
    data['vlan_count'] = vlan_count

    # WAN status from SLA AI
    wan_stats = {
        'status': 'online',
        'primary_health': 95,
        'backup_health': 72,
        'inbound': '0 B',
        'outbound': '0 B'
    }
    try:
        state_file = Path('/run/fortress/slaai-recommendation.json')
        if state_file.exists():
            with open(state_file, 'r') as f:
                sla = json_mod.load(f)
                wan_stats['primary_health'] = int(sla.get('primary_health', 0.95) * 100)
                wan_stats['backup_health'] = int(sla.get('backup_health', 0.72) * 100)
                wan_stats['status'] = 'online' if sla.get('active_interface') == sla.get('primary_interface') else 'backup'
    except Exception:
        pass
    data['wan'] = wan_stats

    # Tunnel status
    tunnel_status = {'state': 'unconfigured', 'hostname': None}
    try:
        tunnel_file = Path('/opt/hookprobe/fortress/tunnel/config.json')
        if tunnel_file.exists():
            with open(tunnel_file, 'r') as f:
                tc = json_mod.load(f)
                tunnel_status = {'state': 'configured', 'hostname': tc.get('hostname')}
    except Exception:
        pass
    data['tunnel'] = tunnel_status

    # Notification count (recent threats)
    notification_count = 0
    try:
        threats_file = Path('/opt/hookprobe/fortress/data/recent_threats.json')
        if threats_file.exists():
            with open(threats_file, 'r') as f:
                notification_count = len(json_mod.load(f)[:5])
    except Exception:
        pass
    data['notification_count'] = notification_count

    return jsonify(data)


# ========================================
# VLAN Management API
# ========================================

@api_bp.route('/vlans')
@login_required
@db_required
def list_vlans():
    """List all VLANs."""
    vlan_mgr = get_vlan_manager()
    vlans = vlan_mgr.get_vlans()

    device_counts = get_db().get_device_count_by_vlan()
    for vlan in vlans:
        vlan['device_count'] = device_counts.get(vlan['vlan_id'], 0)

    return jsonify({'vlans': vlans})


@api_bp.route('/vlans/<int:vlan_id>')
@login_required
@db_required
def get_vlan(vlan_id):
    """Get VLAN details."""
    vlan_mgr = get_vlan_manager()
    vlan = get_db().get_vlan(vlan_id)

    if not vlan:
        return jsonify({'error': 'VLAN not found'}), 404

    status = vlan_mgr.get_vlan_status(vlan_id)
    vlan['status'] = {
        'interface_up': status.interface_up if status else False,
        'dhcp_running': status.dhcp_running if status else False,
        'device_count': status.device_count if status else 0,
    }

    return jsonify(vlan)


@api_bp.route('/vlans/<int:vlan_id>', methods=['PUT'])
@login_required
@operator_required
@db_required
def update_vlan(vlan_id):
    """Update VLAN configuration."""
    data = request.get_json() or {}

    vlan_mgr = get_vlan_manager()
    success = vlan_mgr.update_vlan_config(vlan_id, **data)

    if success:
        get_db().audit_log(
            user_id=current_user.id,
            action='vlan_updated',
            resource_type='vlan',
            resource_id=str(vlan_id),
            details=data,
            ip_address=request.remote_addr
        )
        return jsonify({'success': True})

    return jsonify({'error': 'Failed to update VLAN'}), 400


@api_bp.route('/vlans/<int:vlan_id>/stats')
@login_required
@db_required
def get_vlan_stats(vlan_id):
    """Get VLAN traffic statistics."""
    vlan_mgr = get_vlan_manager()
    stats = vlan_mgr.get_vlan_stats(vlan_id)
    return jsonify(stats)


# ========================================
# Device Management API
# ========================================

@api_bp.route('/devices')
@login_required
def list_devices():
    """List all devices.

    Priority 1: Read from qsecbit agent data file (devices.json)
    Priority 2: Fallback to database if available
    """
    from pathlib import Path

    devices = []
    source = 'none'

    # Priority 1: Try to read from qsecbit agent data file
    data_file = Path('/opt/hookprobe/fortress/data/devices.json')
    if data_file.exists():
        try:
            data = json.loads(data_file.read_text())
            if isinstance(data, dict) and 'devices' in data:
                devices = data.get('devices', [])
            elif isinstance(data, list):
                devices = data
            if devices:
                source = 'agent'
        except Exception:
            pass

    # Priority 2: Fallback to database
    if not devices and DB_AVAILABLE:
        try:
            vlan_id = request.args.get('vlan_id', type=int)
            active_only = request.args.get('active', 'false').lower() == 'true'

            device_mgr = get_device_manager()
            devices = device_mgr.get_all_devices(vlan_id=vlan_id, active_only=active_only)
            source = 'database'
        except Exception:
            pass

    for device in devices:
        for key in ['first_seen', 'last_seen']:
            if device.get(key) and not isinstance(device[key], str):
                device[key] = str(device[key])

    # Merge D2D cluster colors if available
    d2d_colors = {}
    try:
        from aiochi_bubble_client import get_device_colors as _get_d2d_colors
        d2d_colors = _get_d2d_colors()
    except (ImportError, Exception):
        pass

    if d2d_colors:
        for device in devices:
            mac = device.get('mac', device.get('mac_address', '')).upper()
            if mac in d2d_colors:
                device['d2d_cluster_id'] = d2d_colors[mac].get('cluster_id')
                device['d2d_cluster_color'] = d2d_colors[mac].get('cluster_color')
                device['d2d_ecosystem'] = d2d_colors[mac].get('ecosystem')

    return jsonify({'devices': devices, 'count': len(devices), 'source': source})


@api_bp.route('/devices/<mac_address>')
@login_required
@db_required
def get_device(mac_address):
    """Get device by MAC address."""
    device_mgr = get_device_manager()
    device = device_mgr.get_device(mac_address)

    if not device:
        return jsonify({'error': 'Device not found'}), 404

    for key in ['first_seen', 'last_seen']:
        if device.get(key):
            device[key] = str(device[key])

    return jsonify(device)


@api_bp.route('/devices/<mac_address>/vlan', methods=['PUT'])
@login_required
@operator_required
@db_required
def assign_device_vlan(mac_address):
    """Assign device to a VLAN."""
    data = request.get_json() or {}
    vlan_id = data.get('vlan_id')

    if vlan_id is None:
        return jsonify({'error': 'vlan_id required'}), 400

    vlan_mgr = get_vlan_manager()
    success = vlan_mgr.assign_device_to_vlan(
        mac_address,
        vlan_id,
        reason=f"manual_assignment_by_{current_user.id}"
    )

    if success:
        return jsonify({'success': True})

    return jsonify({'error': 'Failed to assign VLAN'}), 400


@api_bp.route('/devices/<mac_address>/block', methods=['POST'])
@login_required
@operator_required
@db_required
def block_device(mac_address):
    """Block a device."""
    data = request.get_json() or {}
    reason = data.get('reason', 'manual_block')

    device_mgr = get_device_manager()
    success = device_mgr.block_device(mac_address, reason=reason)

    if success:
        return jsonify({'success': True})

    return jsonify({'error': 'Failed to block device'}), 400


@api_bp.route('/devices/<mac_address>/unblock', methods=['POST'])
@login_required
@operator_required
@db_required
def unblock_device(mac_address):
    """Unblock a device."""
    device_mgr = get_device_manager()
    success = device_mgr.unblock_device(mac_address)

    if success:
        return jsonify({'success': True})

    return jsonify({'error': 'Failed to unblock device'}), 400


@api_bp.route('/devices/discover', methods=['POST'])
@login_required
@operator_required
@db_required
def discover_devices():
    """Trigger device discovery scan."""
    device_mgr = get_device_manager()
    discovered = device_mgr.discover_devices()

    return jsonify({
        'discovered': len(discovered),
        'new': len([d for d in discovered if d.get('is_new')]),
        'devices': discovered
    })


@api_bp.route('/devices/export')
@login_required
@db_required
def export_devices():
    """Export device inventory."""
    format = request.args.get('format', 'json')

    device_mgr = get_device_manager()

    if format == 'csv':
        csv_data = device_mgr.export_inventory_csv()
        return csv_data, 200, {
            'Content-Type': 'text/csv',
            'Content-Disposition': 'attachment; filename=devices.csv'
        }
    else:
        json_data = device_mgr.export_inventory_json()
        return json_data, 200, {
            'Content-Type': 'application/json',
            'Content-Disposition': 'attachment; filename=devices.json'
        }


@api_bp.route('/devices/counts')
@login_required
@db_required
def device_counts():
    """Get device count summary."""
    device_mgr = get_device_manager()
    counts = device_mgr.get_device_count()
    return jsonify(counts)


# ========================================
# Security / QSecBit API
# ========================================

@api_bp.route('/security/qsecbit')
@login_required
@db_required
def get_qsecbit():
    """Get current QSecBit score."""
    db = get_db()
    qsecbit = db.get_latest_qsecbit()

    if qsecbit:
        qsecbit['score'] = float(qsecbit['score'])
        if qsecbit.get('recorded_at'):
            qsecbit['recorded_at'] = str(qsecbit['recorded_at'])
        return jsonify(qsecbit)

    return jsonify({
        'score': 0.85,
        'rag_status': 'GREEN',
        'components': {},
        'message': 'No QSecBit data available'
    })


@api_bp.route('/security/threats')
@login_required
@db_required
def get_threats():
    """Get recent threats."""
    hours = request.args.get('hours', 24, type=int)
    limit = request.args.get('limit', 100, type=int)

    db = get_db()
    threats = db.get_recent_threats(hours=hours, limit=limit)

    for threat in threats:
        if threat.get('detected_at'):
            threat['detected_at'] = str(threat['detected_at'])
        if threat.get('source_ip'):
            threat['source_ip'] = str(threat['source_ip'])

    return jsonify({'threats': threats, 'count': len(threats)})


@api_bp.route('/security/threats/summary')
@login_required
@db_required
def get_threat_summary():
    """Get threat summary for dashboard."""
    hours = request.args.get('hours', 24, type=int)

    db = get_db()
    summary = db.get_threat_summary(hours=hours)

    return jsonify(summary)


# ========================================
# DNS Statistics API
# ========================================

@api_bp.route('/dns/stats')
@login_required
@db_required
def get_dns_stats():
    """Get DNS query statistics."""
    hours = request.args.get('hours', 24, type=int)

    db = get_db()
    stats = db.get_dns_stats(hours=hours)

    return jsonify(stats)


@api_bp.route('/dns/blocked')
@login_required
@db_required
def get_blocked_domains():
    """Get top blocked domains."""
    limit = request.args.get('limit', 10, type=int)

    db = get_db()
    domains = db.get_top_blocked_domains(limit=limit)

    return jsonify({'domains': domains})


# ========================================
# AI Fingerprinting API (Proprietary)
# ========================================

# Lazy import for fingerprinting modules
FINGERPRINT_AVAILABLE = False
try:
    from products.fortress.lib import (
        get_unified_fingerprint_engine,
        get_ml_fingerprint_classifier,
    )
    FINGERPRINT_AVAILABLE = True
except ImportError:
    pass


def fingerprint_required(f):
    """Decorator to check fingerprinting availability."""
    from functools import wraps
    @wraps(f)
    def decorated(*args, **kwargs):
        if not FINGERPRINT_AVAILABLE:
            return jsonify({'error': 'Fingerprinting engine not available'}), 503
        return f(*args, **kwargs)
    return decorated


@api_bp.route('/fingerprint/status')
@login_required
def fingerprint_status():
    """Get fingerprinting engine status."""
    from pathlib import Path

    status = {
        'engine_available': FINGERPRINT_AVAILABLE,
        'fingerbank_enabled': False,
        'fingerbank_requests_today': 0,
        'ml_model_loaded': False,
        'total_fingerprints': 0,
        'accuracy': 0.0
    }

    # Check Fingerbank API status
    try:
        fb_config = Path('/etc/hookprobe/fingerbank.json')
        if fb_config.exists():
            fb_data = json.loads(fb_config.read_text())
            status['fingerbank_enabled'] = fb_data.get('enabled', False)
            status['fingerbank_requests_today'] = fb_data.get('requests_today', 0)
    except Exception:
        pass

    # Check ML model status
    try:
        model_dir = Path('/var/lib/hookprobe/ml_fingerprint_models')
        if model_dir.exists():
            models = list(model_dir.glob('*.joblib')) + list(model_dir.glob('*.pkl'))
            status['ml_model_loaded'] = len(models) > 0
    except Exception:
        pass

    # Get fingerprint count from database
    try:
        fp_db = Path('/var/lib/hookprobe/fingerprint.db')
        if fp_db.exists():
            import sqlite3
            conn = sqlite3.connect(str(fp_db))
            cursor = conn.cursor()
            cursor.execute('SELECT COUNT(*) FROM fingerprints')
            status['total_fingerprints'] = cursor.fetchone()[0]
            cursor.execute('SELECT AVG(confidence) FROM fingerprints WHERE confidence > 0')
            avg = cursor.fetchone()[0]
            status['accuracy'] = round(avg * 100, 1) if avg else 0.0
            conn.close()
    except Exception:
        pass

    return jsonify(status)


@api_bp.route('/fingerprint/device/<mac_address>')
@login_required
@fingerprint_required
def fingerprint_device(mac_address):
    """Get device fingerprint details."""
    engine = get_unified_fingerprint_engine()
    result = engine.get_device_fingerprint(mac_address)

    if not result:
        return jsonify({'error': 'Device fingerprint not found'}), 404

    return jsonify(result)


@api_bp.route('/fingerprint/device/<mac_address>/reclassify', methods=['POST'])
@login_required
@operator_required
@fingerprint_required
def reclassify_device(mac_address):
    """Force reclassification of a device."""
    engine = get_unified_fingerprint_engine()
    result = engine.reclassify_device(mac_address)

    if result:
        return jsonify({
            'success': True,
            'device_type': result.get('device_type'),
            'confidence': result.get('confidence'),
            'policy': result.get('recommended_policy')
        })

    return jsonify({'error': 'Reclassification failed'}), 400


@api_bp.route('/fingerprint/feedback', methods=['POST'])
@login_required
@operator_required
@fingerprint_required
def submit_fingerprint_feedback():
    """Submit feedback for active learning.

    Used when admin corrects a device classification.
    """
    data = request.get_json() or {}
    mac_address = data.get('mac_address')
    correct_type = data.get('correct_type')
    correct_vendor = data.get('correct_vendor')

    if not mac_address or not correct_type:
        return jsonify({'error': 'mac_address and correct_type required'}), 400

    classifier = get_ml_fingerprint_classifier()
    success = classifier.submit_feedback(
        mac_address=mac_address,
        correct_type=correct_type,
        correct_vendor=correct_vendor,
        submitted_by=current_user.id
    )

    if success:
        return jsonify({'success': True, 'message': 'Feedback recorded for active learning'})

    return jsonify({'error': 'Failed to record feedback'}), 400


@api_bp.route('/fingerprint/stats')
@login_required
def fingerprint_stats():
    """Get fingerprinting statistics."""
    from pathlib import Path

    stats = {
        'total_devices': 0,
        'identified': 0,
        'unidentified': 0,
        'by_category': {},
        'by_vendor': {},
        'accuracy_trend': []
    }

    try:
        fp_db = Path('/var/lib/hookprobe/fingerprint.db')
        if fp_db.exists():
            import sqlite3
            conn = sqlite3.connect(str(fp_db))
            cursor = conn.cursor()

            # Total and identification counts
            cursor.execute('SELECT COUNT(*) FROM fingerprints')
            stats['total_devices'] = cursor.fetchone()[0]

            cursor.execute('SELECT COUNT(*) FROM fingerprints WHERE confidence >= 0.5')
            stats['identified'] = cursor.fetchone()[0]

            stats['unidentified'] = stats['total_devices'] - stats['identified']

            # By category
            cursor.execute('''
                SELECT device_category, COUNT(*) as cnt
                FROM fingerprints
                WHERE device_category IS NOT NULL
                GROUP BY device_category
                ORDER BY cnt DESC
            ''')
            stats['by_category'] = {row[0]: row[1] for row in cursor.fetchall()}

            # By vendor
            cursor.execute('''
                SELECT vendor, COUNT(*) as cnt
                FROM fingerprints
                WHERE vendor IS NOT NULL
                GROUP BY vendor
                ORDER BY cnt DESC
                LIMIT 10
            ''')
            stats['by_vendor'] = {row[0]: row[1] for row in cursor.fetchall()}

            conn.close()
    except Exception:
        pass

    return jsonify(stats)


# ========================================
# Ecosystem Bubble API (via AIOCHI container)
# ========================================

# Use AIOCHI bubble API client (consolidated in aiochi-bubble container)
BUBBLE_AVAILABLE = False
try:
    from aiochi_bubble_client import (
        get_aiochi_bubble_client,
        get_ecosystem_bubbles as get_aiochi_bubbles,
        is_aiochi_available,
    )
    if is_aiochi_available():
        BUBBLE_AVAILABLE = True
except ImportError:
    pass

def get_ecosystem_bubble_manager():
    """Get AIOCHI bubble client (compatibility wrapper)."""
    return get_aiochi_bubble_client() if BUBBLE_AVAILABLE else None


def bubble_required(f):
    """Decorator to check bubble manager availability."""
    from functools import wraps
    @wraps(f)
    def decorated(*args, **kwargs):
        if not BUBBLE_AVAILABLE:
            return jsonify({'error': 'Ecosystem Bubble not available'}), 503
        return f(*args, **kwargs)
    return decorated


@api_bp.route('/bubbles')
@login_required
def list_bubbles():
    """List all detected ecosystem bubbles."""
    from pathlib import Path

    bubbles = []

    try:
        bubble_db = Path('/var/lib/hookprobe/ecosystem_bubbles.db')
        if bubble_db.exists():
            import sqlite3
            conn = sqlite3.connect(str(bubble_db))
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()

            cursor.execute('''
                SELECT bubble_id, name, ecosystem, state, confidence,
                       device_count, created_at, updated_at
                FROM bubbles
                WHERE state != 'DISSOLVED'
                ORDER BY updated_at DESC
            ''')

            for row in cursor.fetchall():
                bubbles.append({
                    'bubble_id': row['bubble_id'],
                    'name': row['name'],
                    'ecosystem': row['ecosystem'],
                    'state': row['state'],
                    'confidence': row['confidence'],
                    'device_count': row['device_count'],
                    'created_at': row['created_at'],
                    'updated_at': row['updated_at']
                })

            conn.close()
    except Exception:
        pass

    return jsonify({'bubbles': bubbles, 'count': len(bubbles)})


@api_bp.route('/bubbles/<bubble_id>')
@login_required
@bubble_required
def get_bubble(bubble_id):
    """Get bubble details including member devices."""
    manager = get_ecosystem_bubble_manager()
    bubble = manager.get_bubble(bubble_id)

    if not bubble:
        return jsonify({'error': 'Bubble not found'}), 404

    return jsonify(bubble)


@api_bp.route('/bubbles/<bubble_id>/devices')
@login_required
@bubble_required
def get_bubble_devices(bubble_id):
    """Get devices in a bubble."""
    manager = get_ecosystem_bubble_manager()
    devices = manager.get_bubble_devices(bubble_id)

    return jsonify({'devices': devices, 'count': len(devices)})


@api_bp.route('/bubbles/<bubble_id>/rules')
@login_required
@bubble_required
def get_bubble_rules(bubble_id):
    """Get SDN/OpenFlow rules for a bubble."""
    manager = get_ecosystem_bubble_manager()
    rules = manager.get_bubble_rules(bubble_id)

    return jsonify({'rules': rules})


@api_bp.route('/bubbles/stats')
@login_required
def bubble_stats():
    """Get ecosystem bubble statistics."""
    from pathlib import Path

    stats = {
        'total_bubbles': 0,
        'active_bubbles': 0,
        'dormant_bubbles': 0,
        'by_ecosystem': {},
        'devices_in_bubbles': 0,
        'sdn_rules_active': 0
    }

    try:
        bubble_db = Path('/var/lib/hookprobe/ecosystem_bubbles.db')
        if bubble_db.exists():
            import sqlite3
            conn = sqlite3.connect(str(bubble_db))
            cursor = conn.cursor()

            cursor.execute('SELECT COUNT(*) FROM bubbles')
            stats['total_bubbles'] = cursor.fetchone()[0]

            cursor.execute("SELECT COUNT(*) FROM bubbles WHERE state = 'ACTIVE'")
            stats['active_bubbles'] = cursor.fetchone()[0]

            cursor.execute("SELECT COUNT(*) FROM bubbles WHERE state = 'DORMANT'")
            stats['dormant_bubbles'] = cursor.fetchone()[0]

            cursor.execute('''
                SELECT ecosystem, COUNT(*) as cnt
                FROM bubbles
                WHERE state != 'DISSOLVED'
                GROUP BY ecosystem
            ''')
            stats['by_ecosystem'] = {row[0]: row[1] for row in cursor.fetchall()}

            cursor.execute('SELECT SUM(device_count) FROM bubbles WHERE state = \'ACTIVE\'')
            result = cursor.fetchone()[0]
            stats['devices_in_bubbles'] = result if result else 0

            # Count active SDN rules
            cursor.execute('SELECT COUNT(*) FROM bubble_sdn_rules WHERE active = 1')
            stats['sdn_rules_active'] = cursor.fetchone()[0]

            conn.close()
    except Exception:
        pass

    return jsonify(stats)


# ========================================
# D2D Communication API (Device Coloring)
# ========================================

# Import D2D client
D2D_AVAILABLE = False
try:
    from aiochi_bubble_client import (
        get_d2d_client,
        get_device_colors,
        get_device_cluster_color,
    )
    D2D_AVAILABLE = True
except ImportError:
    pass


def d2d_required(f):
    """Decorator to check D2D client availability."""
    from functools import wraps
    @wraps(f)
    def decorated(*args, **kwargs):
        if not D2D_AVAILABLE:
            return jsonify({'error': 'D2D communication tracking not available'}), 503
        return f(*args, **kwargs)
    return decorated


@api_bp.route('/d2d/colors')
@login_required
def get_d2d_colors():
    """
    Get D2D cluster colors for all devices.

    Returns a mapping of MAC -> cluster color info for coloring devices in UI.
    Each cluster of communicating devices gets a unique color.
    """
    if not D2D_AVAILABLE:
        return jsonify({'colors': {}, 'available': False})

    try:
        colors = get_device_colors()
        return jsonify({
            'colors': colors,
            'count': len(colors),
            'available': True
        })
    except Exception as e:
        logger.exception("Error fetching D2D colors")
        return jsonify({'colors': {}, 'error': 'Failed to fetch D2D colors', 'available': False}), 500


@api_bp.route('/d2d/device/<mac_address>/color')
@login_required
def get_d2d_device_color(mac_address):
    """
    Get D2D cluster color for a specific device.

    Returns the cluster color and communication info for a device.
    """
    if not D2D_AVAILABLE:
        return jsonify({'error': 'D2D not available'}), 503

    try:
        color_info = get_device_cluster_color(mac_address)
        if not color_info:
            return jsonify({
                'mac': mac_address,
                'cluster_id': None,
                'cluster_color': None,
                'message': 'Device not found in D2D tracking'
            })

        return jsonify({
            'mac': mac_address,
            **color_info
        })
    except Exception as e:
        logger.exception("Error fetching D2D color for device")
        return jsonify({'error': 'Failed to fetch D2D device color'}), 500


@api_bp.route('/d2d/clusters')
@login_required
def get_d2d_clusters():
    """
    Get all D2D communication clusters.

    Returns list of clusters, each with a unique color and member devices.
    """
    if not D2D_AVAILABLE:
        return jsonify({'clusters': [], 'available': False})

    try:
        client = get_d2d_client()
        clusters = client.get_communication_clusters()
        return jsonify({
            'clusters': clusters,
            'count': len(clusters),
            'available': True
        })
    except Exception as e:
        logger.exception("Error fetching D2D clusters")
        return jsonify({'clusters': [], 'error': 'Failed to fetch D2D clusters', 'available': False}), 500


@api_bp.route('/d2d/graph')
@login_required
def get_d2d_graph():
    """
    Get D2D communication graph for visualization.

    Returns nodes (devices) and edges (communication links) for graph display.
    """
    if not D2D_AVAILABLE:
        return jsonify({'nodes': [], 'edges': [], 'available': False})

    try:
        client = get_d2d_client()
        graph = client.get_communication_graph()
        return jsonify({
            **graph,
            'available': True
        })
    except Exception as e:
        logger.exception("Error fetching D2D graph")
        return jsonify({'nodes': [], 'edges': [], 'error': 'Failed to fetch D2D graph', 'available': False}), 500


@api_bp.route('/d2d/stats')
@login_required
def get_d2d_stats():
    """Get D2D communication tracking statistics."""
    if not D2D_AVAILABLE:
        return jsonify({'available': False})

    try:
        client = get_d2d_client()
        stats = client.get_stats()
        return jsonify({
            **stats,
            'available': True
        })
    except Exception as e:
        logger.exception("Error fetching D2D stats")
        return jsonify({'error': 'Failed to fetch D2D stats', 'available': False}), 500


@api_bp.route('/presence/status')
@login_required
def presence_status():
    """Get presence sensor status."""
    from pathlib import Path

    status = {
        'mdns_enabled': False,
        'ble_enabled': False,
        'spatial_enabled': True,
        'devices_detected': 0,
        'ecosystems_detected': {}
    }

    try:
        presence_db = Path('/var/lib/hookprobe/presence.db')
        if presence_db.exists():
            import sqlite3
            conn = sqlite3.connect(str(presence_db))
            cursor = conn.cursor()

            cursor.execute('SELECT COUNT(DISTINCT mac_address) FROM presence_events')
            status['devices_detected'] = cursor.fetchone()[0]

            cursor.execute('''
                SELECT ecosystem, COUNT(DISTINCT mac_address) as cnt
                FROM presence_events
                WHERE ecosystem IS NOT NULL
                GROUP BY ecosystem
            ''')
            status['ecosystems_detected'] = {row[0]: row[1] for row in cursor.fetchall()}

            conn.close()

        # Check service status
        import subprocess
        result = subprocess.run(
            ['systemctl', 'is-active', 'fts-presence-sensor'],
            capture_output=True, text=True, timeout=5
        )
        if result.returncode == 0:
            status['mdns_enabled'] = True
            status['ble_enabled'] = True
    except Exception:
        pass

    return jsonify(status)


# ========================================
# Nexus Purple Team Integration API (v1)
# ========================================

# Lazy import for SDN Autopilot
SDN_AUTOPILOT_AVAILABLE = False
try:
    from products.fortress.lib.sdn_autopilot import get_sdn_autopilot
    SDN_AUTOPILOT_AVAILABLE = True
except ImportError:
    pass


@api_bp.route('/v1/alerts', methods=['POST'])
@login_required
def receive_nexus_alert():
    """
    Receive security alerts from Nexus Purple Team.

    Gap #1 Fix: This endpoint receives validation results from Nexus
    after running red/purple team simulations against the digital twin.

    Payload:
    {
        "alert_type": "purple_team_validation",
        "priority": "high|medium|low|critical",
        "simulation_id": "SIM-20260106-103000",
        "defense_score": 72,
        "overall_risk": "HIGH",
        "bubbles_penetrated": 1,
        "recommendations": ["..."],
        "timestamp": "2026-01-06T12:00:00Z"
    }
    """
    data = request.get_json() or {}

    # Validate required fields
    required = ['alert_type', 'priority', 'simulation_id']
    missing = [f for f in required if f not in data]
    if missing:
        return jsonify({'error': f'Missing fields: {missing}'}), 400

    # Store alert
    from pathlib import Path
    alert = {
        'id': f"ALERT-{datetime.now().strftime('%Y%m%d%H%M%S')}",
        'received_at': datetime.now().isoformat(),
        'acknowledged': False,
        **data
    }

    # Persist to file for dashboard (with file locking to prevent race conditions)
    try:
        import fcntl
        alert_file = Path('/opt/hookprobe/fortress/data/purple_team_alerts.json')
        alert_file.parent.mkdir(parents=True, exist_ok=True)

        with open(alert_file, 'a+') as f:
            fcntl.flock(f, fcntl.LOCK_EX)
            f.seek(0)
            content = f.read()
            existing = json.loads(content) if content.strip() else []
            existing.insert(0, alert)
            existing = existing[:100]  # Keep last 100 alerts
            f.seek(0)
            f.truncate()
            f.write(json.dumps(existing, indent=2))
    except Exception as e:
        pass

    # Log high-priority alerts
    import logging
    logger = logging.getLogger(__name__)
    if data.get('priority') in ('high', 'critical'):
        logger.warning(
            f"Purple Team Alert [{data.get('priority')}]: "
            f"Defense Score={data.get('defense_score')}, "
            f"Risk={data.get('overall_risk')}"
        )

    # Trigger immediate action for critical alerts
    if data.get('priority') == 'critical' and data.get('overall_risk') == 'CRITICAL':
        _trigger_emergency_lockdown(data)

    return jsonify({
        'status': 'received',
        'alert_id': alert['id'],
        'message': 'Alert queued for processing'
    }), 201


@api_bp.route('/v1/alerts')
@login_required
def list_nexus_alerts():
    """List recent Purple Team alerts."""
    from pathlib import Path
    try:
        alert_file = Path('/opt/hookprobe/fortress/data/purple_team_alerts.json')
        if alert_file.exists():
            alerts = json.loads(alert_file.read_text())
            return jsonify({'alerts': alerts, 'count': len(alerts)})
    except Exception:
        pass

    return jsonify({'alerts': [], 'count': 0})


@api_bp.route('/v1/alerts/<alert_id>/acknowledge', methods=['POST'])
@login_required
@operator_required
def acknowledge_alert(alert_id):
    """Acknowledge a Purple Team alert."""
    from pathlib import Path
    try:
        alert_file = Path('/opt/hookprobe/fortress/data/purple_team_alerts.json')
        if alert_file.exists():
            alerts = json.loads(alert_file.read_text())
            for alert in alerts:
                if alert.get('id') == alert_id:
                    alert['acknowledged'] = True
                    alert['acknowledged_at'] = datetime.now().isoformat()
                    alert['acknowledged_by'] = current_user.id
                    alert_file.write_text(json.dumps(alerts, indent=2))
                    return jsonify({'success': True})

        return jsonify({'error': 'Alert not found'}), 404
    except Exception as e:
        return jsonify({'error': safe_error_message(e)}), 500


@api_bp.route('/v1/autopilot/optimize', methods=['POST'])
@login_required
@admin_required
def apply_nexus_optimization():
    """
    Apply optimization recommendations from Nexus Purple Team.

    Gap #1 Fix: This endpoint receives optimization parameters from Nexus
    to improve SDN Autopilot bubble assignment accuracy.

    Payload:
    {
        "source": "purple_team",
        "simulation_id": "SIM-20260106-103000",
        "optimizations": [
            {
                "parameter": "temporal_sync_weight",
                "action": "increase",
                "old_value": 0.30,
                "new_value": 0.35,
                "reason": "Meta-regression shows temporal sync underweighted"
            }
        ]
    }
    """
    data = request.get_json() or {}

    if data.get('source') != 'purple_team':
        return jsonify({'error': 'Invalid source - only purple_team allowed'}), 403

    optimizations = data.get('optimizations', [])
    if not optimizations:
        return jsonify({'error': 'No optimizations provided'}), 400

    # Track what we apply
    applied = []
    failed = []

    for opt in optimizations:
        param = opt.get('parameter')
        action = opt.get('action')
        new_value = opt.get('new_value')
        reason = opt.get('reason', 'Purple team recommendation')

        result = _apply_autopilot_optimization(param, action, new_value, reason)
        if result['success']:
            applied.append({
                'parameter': param,
                'action': action,
                'new_value': new_value,
                'applied_at': datetime.now().isoformat()
            })
        else:
            failed.append({
                'parameter': param,
                'error': result.get('error', 'Unknown error')
            })

    # Persist optimization history
    from pathlib import Path
    opt_record = {
        'id': f"OPT-{datetime.now().strftime('%Y%m%d%H%M%S')}",
        'simulation_id': data.get('simulation_id'),
        'timestamp': datetime.now().isoformat(),
        'applied': applied,
        'failed': failed
    }

    # Write to file for auditing
    try:
        opt_file = Path('/opt/hookprobe/fortress/data/autopilot_optimizations.json')
        opt_file.parent.mkdir(parents=True, exist_ok=True)

        existing = []
        if opt_file.exists():
            existing = json.loads(opt_file.read_text())

        existing.insert(0, opt_record)
        existing = existing[:50]  # Keep last 50 optimizations
        opt_file.write_text(json.dumps(existing, indent=2))
    except Exception as e:
        pass

    # Report back to AIOCHI (Gap #2 integration)
    try:
        from products.fortress.lib.aiochi_client import get_aiochi_client
        client = get_aiochi_client()
        client.report_optimization_applied(opt_record)
    except Exception:
        pass

    return jsonify({
        'status': 'processed',
        'optimization_id': opt_record['id'],
        'applied_count': len(applied),
        'failed_count': len(failed),
        'applied': applied,
        'failed': failed
    }), 200 if not failed else 207  # 207 = Multi-Status


@api_bp.route('/v1/autopilot/status')
@login_required
def autopilot_status():
    """Get SDN Autopilot optimization status and history."""
    from pathlib import Path

    status = {
        'autopilot_active': SDN_AUTOPILOT_AVAILABLE,
        'last_optimization': None,
        'recent_optimizations': [],
        'current_weights': {},
        'defense_score_trend': []
    }

    # Load optimization history
    try:
        opt_file = Path('/opt/hookprobe/fortress/data/autopilot_optimizations.json')
        if opt_file.exists():
            opts = json.loads(opt_file.read_text())
            status['recent_optimizations'] = opts[:10]
            if opts:
                status['last_optimization'] = opts[0].get('timestamp')
    except Exception:
        pass

    # Load current weights from autopilot config
    try:
        config_file = Path('/etc/hookprobe/autopilot.conf')
        if config_file.exists():
            with open(config_file, 'r') as f:
                for line in f:
                    if '=' in line and not line.strip().startswith('#'):
                        key, value = line.strip().split('=', 1)
                        key = key.strip()
                        value = value.strip().strip('"\'')
                        if key.endswith('_weight') or key.endswith('_interval'):
                            try:
                                status['current_weights'][key] = float(value)
                            except ValueError:
                                status['current_weights'][key] = value
    except Exception:
        pass

    # Load defense score trend from alerts
    try:
        alert_file = Path('/opt/hookprobe/fortress/data/purple_team_alerts.json')
        if alert_file.exists():
            alerts = json.loads(alert_file.read_text())
            for alert in alerts[:20]:
                if 'defense_score' in alert:
                    status['defense_score_trend'].append({
                        'timestamp': alert.get('received_at'),
                        'score': alert.get('defense_score'),
                        'risk': alert.get('overall_risk')
                    })
    except Exception:
        pass

    return jsonify(status)


@api_bp.route('/v1/defense/outcome', methods=['POST'])
@login_required
def report_defense_outcome():
    """
    Report actual defense outcome from SDN Autopilot.

    Gap #6 Fix: SDN Autopilot reports real defense outcomes to enable
    Nexus to compare simulated vs actual detection rates.

    Payload:
    {
        "event_type": "defense_outcome",
        "attack_type": "ter_replay",
        "detected": true,
        "blocked": true,
        "detection_method": "NEURO protocol resonance drift",
        "response_action": "quarantine",
        "mac": "aa:bb:cc:dd:ee:ff",
        "timestamp": "2026-01-06T12:00:00Z"
    }
    """
    from pathlib import Path
    data = request.get_json() or {}

    # Store outcome
    outcome = {
        'id': f"DEF-{datetime.now().strftime('%Y%m%d%H%M%S%f')[:17]}",
        'received_at': datetime.now().isoformat(),
        **data
    }

    # Persist for Nexus to fetch (with file locking to prevent race conditions)
    try:
        import fcntl
        outcome_file = Path('/opt/hookprobe/fortress/data/defense_outcomes.json')
        outcome_file.parent.mkdir(parents=True, exist_ok=True)

        with open(outcome_file, 'a+') as f:
            fcntl.flock(f, fcntl.LOCK_EX)
            f.seek(0)
            content = f.read()
            existing = json.loads(content) if content.strip() else []
            existing.insert(0, outcome)
            existing = existing[:500]  # Keep more outcomes for analysis
            f.seek(0)
            f.truncate()
            f.write(json.dumps(existing, indent=2))
    except Exception:
        pass

    return jsonify({
        'status': 'received',
        'outcome_id': outcome['id']
    }), 201


@api_bp.route('/v1/defense/outcomes')
@login_required
def list_defense_outcomes():
    """List recent defense outcomes for Nexus feedback loop."""
    from pathlib import Path
    limit = request.args.get('limit', 100, type=int)
    since = request.args.get('since')  # ISO timestamp

    try:
        outcome_file = Path('/opt/hookprobe/fortress/data/defense_outcomes.json')
        if outcome_file.exists():
            outcomes = json.loads(outcome_file.read_text())

            # Filter by timestamp if provided
            if since:
                outcomes = [o for o in outcomes if o.get('received_at', '') > since]

            outcomes = outcomes[:limit]
            return jsonify({'outcomes': outcomes, 'count': len(outcomes)})
    except Exception:
        pass

    return jsonify({'outcomes': [], 'count': 0})


def _apply_autopilot_optimization(
    parameter: str,
    action: str,
    new_value,
    reason: str
):
    """Apply a single autopilot optimization parameter."""
    from pathlib import Path
    config_file = Path('/etc/hookprobe/autopilot.conf')

    # Whitelist of allowed parameters
    ALLOWED_PARAMS = {
        'temporal_sync_weight',
        'd2d_affinity_weight',
        'nse_resonance_weight',
        'nse_heartbeat_interval_ms',
        'ter_replay_window_ms',
        'entropy_threshold',
        'mac_binding_strict',
        'mdns_validation_enabled',
        'temporal_mimicry_detection',
        'dhcp_fingerprint_validation',
    }

    if parameter not in ALLOWED_PARAMS:
        return {'success': False, 'error': f'Parameter not allowed: {parameter}'}

    # Sanitize value and reason to prevent config injection
    safe_value = str(new_value).replace('\n', '').replace('\r', '').strip()
    safe_reason = str(reason).replace('\n', ' ').replace('\r', '').replace('#', '').strip()[:200]

    # Validate value is a reasonable config value (numbers, booleans, simple strings)
    import re as _re
    if not _re.match(r'^[a-zA-Z0-9._\-]+$', safe_value):
        return {'success': False, 'error': 'Invalid value format'}

    try:
        # Read current config
        lines = []
        if config_file.exists():
            with open(config_file, 'r') as f:
                lines = f.readlines()

        # Update or add parameter
        found = False
        for i, line in enumerate(lines):
            if line.strip().startswith(f'{parameter}='):
                lines[i] = f'{parameter}={safe_value}  # Updated by purple_team: {safe_reason}\n'
                found = True
                break

        if not found:
            lines.append(f'{parameter}={safe_value}  # Added by purple_team: {safe_reason}\n')

        # Write updated config
        config_file.parent.mkdir(parents=True, exist_ok=True)
        with open(config_file, 'w') as f:
            f.writelines(lines)

        # Reload autopilot if available
        if SDN_AUTOPILOT_AVAILABLE:
            try:
                autopilot = get_sdn_autopilot()
                autopilot.reload_config()
            except Exception:
                pass

        import logging
        logging.getLogger(__name__).info(
            f"Applied autopilot optimization: {parameter}={new_value} ({reason})"
        )
        return {'success': True}

    except Exception as e:
        return {'success': False, 'error': safe_error_message(e)}


def _trigger_emergency_lockdown(alert_data):
    """Trigger emergency lockdown for critical alerts."""
    from pathlib import Path
    import logging
    import subprocess

    logging.getLogger(__name__).critical(
        f"EMERGENCY LOCKDOWN triggered by Purple Team alert"
    )

    try:
        # Write lockdown flag for SDN Autopilot
        lockdown_file = Path('/run/fortress/emergency_lockdown')
        lockdown_file.parent.mkdir(parents=True, exist_ok=True)
        lockdown_file.write_text(json.dumps({
            'triggered_at': datetime.now().isoformat(),
            'reason': 'Purple team critical alert',
            'simulation_id': alert_data.get('simulation_id'),
            'defense_score': alert_data.get('defense_score'),
        }))

        # Signal systemd to trigger lockdown (if service exists)
        subprocess.run(
            ['systemctl', 'start', 'fortress-lockdown.service'],
            capture_output=True,
            timeout=5
        )
    except Exception:
        pass
